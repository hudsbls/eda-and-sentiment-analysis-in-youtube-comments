{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from langdetect import detect\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "hp = pd.read_csv('analysis/headphones_yt_2.csv')\n",
    "hp.drop(['Title', 'Description', 'Channel'], axis='columns', inplace=True)\n",
    "hp.rename(columns = {'Comment': 'text'}, inplace = True)\n",
    "hp.text = hp.text.apply(str)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "hp.shape\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1368, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Detect only english comments"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def detect_en(text):\n",
    "    \"\"\"Function to detect just english text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Open contractions, example: \"don't\": \"do not\":"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Dictionary of English Contractions\n",
    "contractions_dict = { \n",
    "                     \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\", \"couldn`t\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\", \"Ive\": \"I have\", \"Im\": \"I am\", \"i'd\": \"I do\", \n",
    "                     \"thats\": \"that is\", \"i'm\": \"I am\", \"Youâ€˜re\": \"you are\", \"Thatâ€™s\": \"that is\", \"Iâ€™m\": \"I am\", \"/\": \" \"}\n",
    "\n",
    "# Function for expanding contractions\n",
    "def expand_contractions(self, contractions_dict=contractions_dict):\n",
    "    \"\"\"Function to replace contractions to the open format\n",
    "    \"\"\"\n",
    "# Regular expression for finding contractions\n",
    "    contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, self)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Replace abbreviations for the real form"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "## chat words\n",
    "chat_words_str = \"\"\"\n",
    "AFAIK=As Far As I Know\n",
    "AFK=Away From Keyboard\n",
    "ASAP=As Soon As Possible\n",
    "ATK=At The Keyboard\n",
    "ATM=At The Moment\n",
    "A3=Anytime, Anywhere, Anyplace\n",
    "BAK=Back At Keyboard\n",
    "BBL=Be Back Later\n",
    "BBS=Be Back Soon\n",
    "BFN=Bye For Now\n",
    "B4N=Bye For Now\n",
    "BRB=Be Right Back\n",
    "BRT=Be Right There\n",
    "BTW=By The Way\n",
    "B4=Before\n",
    "B4N=Bye For Now\n",
    "CU=See You\n",
    "CUL8R=See You Later\n",
    "CYA=See You\n",
    "FAQ=Frequently Asked Questions\n",
    "FC=Fingers Crossed\n",
    "FWIW=For What It's Worth\n",
    "FYI=For Your Information\n",
    "GAL=Get A Life\n",
    "GG=Good Game\n",
    "GN=Good Night\n",
    "GMTA=Great Minds Think Alike\n",
    "GR8=Great!\n",
    "G9=Genius\n",
    "IC=I See\n",
    "ICQ=I Seek you (also a chat program)\n",
    "ILU=ILU: I Love You\n",
    "IMHO=In My Honest/Humble Opinion\n",
    "IMO=In My Opinion\n",
    "IOW=In Other Words\n",
    "IRL=In Real Life\n",
    "KISS=Keep It Simple, Stupid\n",
    "LDR=Long Distance Relationship\n",
    "LMAO=Laugh My A.. Off\n",
    "LOL=Laughing Out Loud\n",
    "LTNS=Long Time No See\n",
    "L8R=Later\n",
    "MTE=My Thoughts Exactly\n",
    "M8=Mate\n",
    "NRN=No Reply Necessary\n",
    "OIC=Oh I See\n",
    "PITA=Pain In The A..\n",
    "PRT=Party\n",
    "PRW=Parents Are Watching\n",
    "ROFL=Rolling On The Floor Laughing\n",
    "ROFLOL=Rolling On The Floor Laughing Out Loud\n",
    "ROTFLMAO=Rolling On The Floor Laughing My A.. Off\n",
    "SK8=Skate\n",
    "STATS=Your sex and age\n",
    "ASL=Age, Sex, Location\n",
    "THX=Thank You\n",
    "TTFN=Ta-Ta For Now!\n",
    "TTYL=Talk To You Later\n",
    "U=You\n",
    "U2=You Too\n",
    "U4E=Yours For Ever\n",
    "WB=Welcome Back\n",
    "WTF=What The F...\n",
    "WTG=Way To Go!\n",
    "WUF=Where Are You From?\n",
    "W8=Wait...\n",
    "7K=Sick:-D Laugher\n",
    "\"\"\"\n",
    "chat_words_map_dict = {}\n",
    "chat_words_list = []\n",
    "for line in chat_words_str.split(\"\\n\"):\n",
    "    if line != \"\":\n",
    "        cw = line.split(\"=\")[0]\n",
    "        cw_expanded = line.split(\"=\")[1]\n",
    "        chat_words_list.append(cw)\n",
    "        chat_words_map_dict[cw] = cw_expanded\n",
    "chat_words_list = set(chat_words_list)\n",
    "\n",
    "def chat_words_conversion(text):\n",
    "    \"\"\"Function to replace abbreviations to the whole form\n",
    "    \"\"\"\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words_list:\n",
    "            new_text.append(chat_words_map_dict[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transform entire text to lowercase "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def lower_text(self):\n",
    "    \"\"\" Function to lowercase the text\n",
    "    \"\"\"\n",
    "    return self.lower()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove stopwords and other words"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def remove_stopwords(self):\n",
    "    \"\"\"Function to remove the stopwords\"\"\"\n",
    "\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    #nÃ£o remover palavras importantes\n",
    "    exclude_words = set((\"and\", \"or\", \"no\"))\n",
    "    new_stop_words = stop_words.difference(exclude_words)\n",
    "    return \" \".join([word.lower() for word in str(self).split() if word not in new_stop_words])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove symbols and special characters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def remove_symbols(text):   \n",
    "    \n",
    "    #remover @username \n",
    "    text = re.sub(r'@([^\\s]+)', r'', text)\n",
    "    \n",
    "    #remover pontuaÃ§Ã£o\n",
    "    PUNCT_TO_REMOVE = string.punctuation\n",
    "    text = text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "    \n",
    "    #remover www.* or https?://* \n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ', text)\n",
    "   \n",
    "  \n",
    "    #substituir #word para word(remover hashtag)\n",
    "    text = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
    "    \n",
    "    #remover parentes e conteudo dos parentesis \n",
    "    \"usar ou nÃ£o????\"\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    \n",
    "    #remover todos os outros caracteres (exceto numeros e letras)\n",
    "    text = re.sub(r\"[^\\w\\s]\", '', text)\n",
    "    \n",
    "    #substituir traÃ§o por espaÃ§o:\n",
    "    text = re.sub(r\"([A-z])\\-([A-z])\", r\"\\1 \\2\", text)\n",
    "\n",
    "    #trim\n",
    "    text = text.strip('\\'\"')\n",
    "    \n",
    "    #remover letras em excesso, como happyyyyyyyy fica happyy:\n",
    "    \"precisa usar?\"\n",
    "    rpt_regex = re.compile(r\"(.)\\1{1,}\", re.IGNORECASE)\n",
    "    text = rpt_regex.sub(r\"\\1\\1\", text)\n",
    "    \n",
    "    #codigo dos emojis:\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U0001F1F2\"\n",
    "        u\"\\U0001F1F4\"\n",
    "        u\"\\U0001F620\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    #remover emojis do texto, no futuro podemos substiuir por palavras:\n",
    "    def emoji(text):\n",
    "        text = emoji_pattern.sub(r'', text)\n",
    "        return text\n",
    "    \n",
    "    #remover emoticons:\n",
    "    emoticons = \\\n",
    "    [\n",
    "     ('__positive__',[ ':-)', ':)', '(:', '(-:', \\\n",
    "                       ':-D', ':D', 'X-D', 'XD', 'xD', \\\n",
    "                       '<3', ':\\*', ';-)', ';)', ';-D', ';D', '(;', '(-;', ] ),\\\n",
    "     ('__negative__', [':-(', ':(', '(:', '(-:', ':,(',\\\n",
    "                       ':\\'(', ':\"(', ':((', ] ),\\\n",
    "    ]\n",
    "    \n",
    "    def replace_parenth(arr):\n",
    "        return [text.replace(')', '[)}\\]]').replace('(', '[({\\[]') for text in arr]\n",
    "    \n",
    "    def regex_join(arr):\n",
    "        return '(' + '|'.join( arr ) + ')'\n",
    "\n",
    "    emoticons_regex = [ (repl, re.compile(regex_join(replace_parenth(regx))) ) \\\n",
    "            for (repl, regx) in emoticons ]\n",
    "    \n",
    "    for (repl, regx) in emoticons_regex :\n",
    "        text = re.sub(regx, ' '+repl+' ', text)\n",
    "    \n",
    "    return text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokens are individual terms or words, and tokenization is the process of splitting a string of text into tokens:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def tokenizer(text):\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    return word_list\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Lemmatization: takes the word to its root form, called Lemma. This helps to bring the words into their dictionary form. It is applied to nouns by default. It's more accurate because it uses more informed analysis to create groups of words with similar meanings based on context, so it's complex and takes more time. This is used where we need to retain contextual information.\n",
    "#### Stemming: A technique that takes the word to its root form. It just removes the suffixes from the words. The radical word may not be in the dictionary, that is, it will not necessarily have a meaning. There are two main types of stemmer - Porter Stemmer and Snow Ball Stemmer (advanced version of Porter Stemmer).\n",
    "## In this case, lemmatization is a more suitable operation, as it takes into account the morphological analysis of the word."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def lemmatize_words(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    sentence_words = tokenizer(text)\n",
    "    for word in sentence_words:\n",
    "        sentence_words.remove(word)\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Apply all the functions above to clean the text data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def cleaning_process(df):\n",
    "    \n",
    "    df['english'] = df['text'].apply(detect_en)\n",
    "    df['no_contractions'] = df['text'].apply(expand_contractions) \n",
    "    df['no_chat'] = df['no_contractions'].apply(chat_words_conversion)\n",
    "    df['lower_text'] = df['no_chat'].apply(lower_text)   \n",
    "    df['no_stop'] = df['lower_text'].apply(remove_stopwords)\n",
    "    df['no_symbols'] = df['no_stop'].apply(remove_symbols) \n",
    "    df['lemma'] = df['no_symbols'].apply(lemmatize_words)\n",
    "    df['token'] = df['lemma'].apply(tokenizer)\n",
    "\n",
    "\n",
    "\n",
    "    df = df.drop(['no_contractions', 'no_chat', 'lower_text', 'no_stop', 'no_symbols'], axis='columns', inplace=True)\n",
    "    return df  \n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "cleaning_process(hp)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "hp.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  english  \\\n",
       "0  I am also a big fan of Beyerdynamic, I LOVE my...     True   \n",
       "1  The 880s are a very unique and special headpho...     True   \n",
       "2                                  2 pros chatting ðŸ˜…     True   \n",
       "3   @In The Mix  Im considering buying  the DT770...     True   \n",
       "4   @In The Mix  I use 770s for DJing since I nee...     True   \n",
       "\n",
       "                                               lemma  \\\n",
       "0  also big fan beyerdynamic love dt880s pro make...   \n",
       "1  880s unique and special headphone take time ge...   \n",
       "2                                         2 pro chat   \n",
       "3   mix consider buy dt770 produce go thanks mention   \n",
       "4  mix use 770s djing since need isolation and 99...   \n",
       "\n",
       "                                               token  \n",
       "0  [also, big, fan, beyerdynamic, love, dt880s, p...  \n",
       "1  [880s, unique, and, special, headphone, take, ...  \n",
       "2                                     [2, pro, chat]  \n",
       "3  [mix, consider, buy, dt770, produce, go, thank...  \n",
       "4  [mix, use, 770s, djing, since, need, isolation...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>english</th>\n",
       "      <th>lemma</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am also a big fan of Beyerdynamic, I LOVE my...</td>\n",
       "      <td>True</td>\n",
       "      <td>also big fan beyerdynamic love dt880s pro make...</td>\n",
       "      <td>[also, big, fan, beyerdynamic, love, dt880s, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The 880s are a very unique and special headpho...</td>\n",
       "      <td>True</td>\n",
       "      <td>880s unique and special headphone take time ge...</td>\n",
       "      <td>[880s, unique, and, special, headphone, take, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 pros chatting ðŸ˜…</td>\n",
       "      <td>True</td>\n",
       "      <td>2 pro chat</td>\n",
       "      <td>[2, pro, chat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@In The Mix  Im considering buying  the DT770...</td>\n",
       "      <td>True</td>\n",
       "      <td>mix consider buy dt770 produce go thanks mention</td>\n",
       "      <td>[mix, consider, buy, dt770, produce, go, thank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@In The Mix  I use 770s for DJing since I nee...</td>\n",
       "      <td>True</td>\n",
       "      <td>mix use 770s djing since need isolation and 99...</td>\n",
       "      <td>[mix, use, 770s, djing, since, need, isolation...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove empty cells, short sentences or non-english lines"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def no_english_drop(df):    \n",
    "    df = df.drop(df[df['english'] == False ].index, inplace=True)\n",
    "    return df\n",
    "no_english_drop(hp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "hp"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text  english  \\\n",
       "0     I am also a big fan of Beyerdynamic, I LOVE my...     True   \n",
       "1     The 880s are a very unique and special headpho...     True   \n",
       "2                                     2 pros chatting ðŸ˜…     True   \n",
       "3      @In The Mix  Im considering buying  the DT770...     True   \n",
       "4      @In The Mix  I use 770s for DJing since I nee...     True   \n",
       "...                                                 ...      ...   \n",
       "1361  The wrong title for sure because what is best ...     True   \n",
       "1362  buy a cheap headphones. slap on sonarworks and...     True   \n",
       "1363  I purchased m40x yesterday and wasn't satisfie...     True   \n",
       "1364  Compared to the beats headphones which blast b...     True   \n",
       "1365  Hey,  is Audio-Technica ATH-M50X really worth ...     True   \n",
       "\n",
       "                                                  lemma  \\\n",
       "0     also big fan beyerdynamic love dt880s pro make...   \n",
       "1     880s unique and special headphone take time ge...   \n",
       "2                                            2 pro chat   \n",
       "3      mix consider buy dt770 produce go thanks mention   \n",
       "4     mix use 770s djing since need isolation and 99...   \n",
       "...                                                 ...   \n",
       "1361  wrong title sure best production and mixing al...   \n",
       "1362  buy cheap headphone slap sonarworks and make b...   \n",
       "1363  purchase m40x yesterday and satisfied bass lik...   \n",
       "1364  compare beat headphone blast bass m40x flat so...   \n",
       "1365  hey audiotechnica athm50x really worth buy rea...   \n",
       "\n",
       "                                                  token  \n",
       "0     [also, big, fan, beyerdynamic, love, dt880s, p...  \n",
       "1     [880s, unique, and, special, headphone, take, ...  \n",
       "2                                        [2, pro, chat]  \n",
       "3     [mix, consider, buy, dt770, produce, go, thank...  \n",
       "4     [mix, use, 770s, djing, since, need, isolation...  \n",
       "...                                                 ...  \n",
       "1361  [wrong, title, sure, best, production, and, mi...  \n",
       "1362  [buy, cheap, headphone, slap, sonarworks, and,...  \n",
       "1363  [purchase, m40x, yesterday, and, satisfied, ba...  \n",
       "1364  [compare, beat, headphone, blast, bass, m40x, ...  \n",
       "1365  [hey, audiotechnica, athm50x, really, worth, b...  \n",
       "\n",
       "[1279 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>english</th>\n",
       "      <th>lemma</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am also a big fan of Beyerdynamic, I LOVE my...</td>\n",
       "      <td>True</td>\n",
       "      <td>also big fan beyerdynamic love dt880s pro make...</td>\n",
       "      <td>[also, big, fan, beyerdynamic, love, dt880s, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The 880s are a very unique and special headpho...</td>\n",
       "      <td>True</td>\n",
       "      <td>880s unique and special headphone take time ge...</td>\n",
       "      <td>[880s, unique, and, special, headphone, take, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 pros chatting ðŸ˜…</td>\n",
       "      <td>True</td>\n",
       "      <td>2 pro chat</td>\n",
       "      <td>[2, pro, chat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@In The Mix  Im considering buying  the DT770...</td>\n",
       "      <td>True</td>\n",
       "      <td>mix consider buy dt770 produce go thanks mention</td>\n",
       "      <td>[mix, consider, buy, dt770, produce, go, thank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@In The Mix  I use 770s for DJing since I nee...</td>\n",
       "      <td>True</td>\n",
       "      <td>mix use 770s djing since need isolation and 99...</td>\n",
       "      <td>[mix, use, 770s, djing, since, need, isolation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>The wrong title for sure because what is best ...</td>\n",
       "      <td>True</td>\n",
       "      <td>wrong title sure best production and mixing al...</td>\n",
       "      <td>[wrong, title, sure, best, production, and, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>buy a cheap headphones. slap on sonarworks and...</td>\n",
       "      <td>True</td>\n",
       "      <td>buy cheap headphone slap sonarworks and make b...</td>\n",
       "      <td>[buy, cheap, headphone, slap, sonarworks, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>I purchased m40x yesterday and wasn't satisfie...</td>\n",
       "      <td>True</td>\n",
       "      <td>purchase m40x yesterday and satisfied bass lik...</td>\n",
       "      <td>[purchase, m40x, yesterday, and, satisfied, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>Compared to the beats headphones which blast b...</td>\n",
       "      <td>True</td>\n",
       "      <td>compare beat headphone blast bass m40x flat so...</td>\n",
       "      <td>[compare, beat, headphone, blast, bass, m40x, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>Hey,  is Audio-Technica ATH-M50X really worth ...</td>\n",
       "      <td>True</td>\n",
       "      <td>hey audiotechnica athm50x really worth buy rea...</td>\n",
       "      <td>[hey, audiotechnica, athm50x, really, worth, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1279 rows Ã— 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def remove_small_sentence(df):\n",
    "    \"\"\"Function to remove sentences smaller than 3 words\n",
    "    \"\"\"\n",
    "    wantedRows = df[df['lemma'].str.split().str.len()<=3].index \n",
    "    df =  df.drop(wantedRows, axis = 0, inplace=True)       \n",
    "    return df\n",
    "remove_small_sentence(hp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "hp"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text  english  \\\n",
       "0     I am also a big fan of Beyerdynamic, I LOVE my...     True   \n",
       "1     The 880s are a very unique and special headpho...     True   \n",
       "3      @In The Mix  Im considering buying  the DT770...     True   \n",
       "4      @In The Mix  I use 770s for DJing since I nee...     True   \n",
       "5                   Producer collab? Maybe? No? Ok...ðŸ˜‚ðŸ˜‚     True   \n",
       "...                                                 ...      ...   \n",
       "1361  The wrong title for sure because what is best ...     True   \n",
       "1362  buy a cheap headphones. slap on sonarworks and...     True   \n",
       "1363  I purchased m40x yesterday and wasn't satisfie...     True   \n",
       "1364  Compared to the beats headphones which blast b...     True   \n",
       "1365  Hey,  is Audio-Technica ATH-M50X really worth ...     True   \n",
       "\n",
       "                                                  lemma  \\\n",
       "0     also big fan beyerdynamic love dt880s pro make...   \n",
       "1     880s unique and special headphone take time ge...   \n",
       "3      mix consider buy dt770 produce go thanks mention   \n",
       "4     mix use 770s djing since need isolation and 99...   \n",
       "5                           producer collab maybe no ok   \n",
       "...                                                 ...   \n",
       "1361  wrong title sure best production and mixing al...   \n",
       "1362  buy cheap headphone slap sonarworks and make b...   \n",
       "1363  purchase m40x yesterday and satisfied bass lik...   \n",
       "1364  compare beat headphone blast bass m40x flat so...   \n",
       "1365  hey audiotechnica athm50x really worth buy rea...   \n",
       "\n",
       "                                                  token  \n",
       "0     [also, big, fan, beyerdynamic, love, dt880s, p...  \n",
       "1     [880s, unique, and, special, headphone, take, ...  \n",
       "3     [mix, consider, buy, dt770, produce, go, thank...  \n",
       "4     [mix, use, 770s, djing, since, need, isolation...  \n",
       "5                     [producer, collab, maybe, no, ok]  \n",
       "...                                                 ...  \n",
       "1361  [wrong, title, sure, best, production, and, mi...  \n",
       "1362  [buy, cheap, headphone, slap, sonarworks, and,...  \n",
       "1363  [purchase, m40x, yesterday, and, satisfied, ba...  \n",
       "1364  [compare, beat, headphone, blast, bass, m40x, ...  \n",
       "1365  [hey, audiotechnica, athm50x, really, worth, b...  \n",
       "\n",
       "[1129 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>english</th>\n",
       "      <th>lemma</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am also a big fan of Beyerdynamic, I LOVE my...</td>\n",
       "      <td>True</td>\n",
       "      <td>also big fan beyerdynamic love dt880s pro make...</td>\n",
       "      <td>[also, big, fan, beyerdynamic, love, dt880s, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The 880s are a very unique and special headpho...</td>\n",
       "      <td>True</td>\n",
       "      <td>880s unique and special headphone take time ge...</td>\n",
       "      <td>[880s, unique, and, special, headphone, take, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@In The Mix  Im considering buying  the DT770...</td>\n",
       "      <td>True</td>\n",
       "      <td>mix consider buy dt770 produce go thanks mention</td>\n",
       "      <td>[mix, consider, buy, dt770, produce, go, thank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@In The Mix  I use 770s for DJing since I nee...</td>\n",
       "      <td>True</td>\n",
       "      <td>mix use 770s djing since need isolation and 99...</td>\n",
       "      <td>[mix, use, 770s, djing, since, need, isolation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Producer collab? Maybe? No? Ok...ðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>True</td>\n",
       "      <td>producer collab maybe no ok</td>\n",
       "      <td>[producer, collab, maybe, no, ok]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>The wrong title for sure because what is best ...</td>\n",
       "      <td>True</td>\n",
       "      <td>wrong title sure best production and mixing al...</td>\n",
       "      <td>[wrong, title, sure, best, production, and, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>buy a cheap headphones. slap on sonarworks and...</td>\n",
       "      <td>True</td>\n",
       "      <td>buy cheap headphone slap sonarworks and make b...</td>\n",
       "      <td>[buy, cheap, headphone, slap, sonarworks, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>I purchased m40x yesterday and wasn't satisfie...</td>\n",
       "      <td>True</td>\n",
       "      <td>purchase m40x yesterday and satisfied bass lik...</td>\n",
       "      <td>[purchase, m40x, yesterday, and, satisfied, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>Compared to the beats headphones which blast b...</td>\n",
       "      <td>True</td>\n",
       "      <td>compare beat headphone blast bass m40x flat so...</td>\n",
       "      <td>[compare, beat, headphone, blast, bass, m40x, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>Hey,  is Audio-Technica ATH-M50X really worth ...</td>\n",
       "      <td>True</td>\n",
       "      <td>hey audiotechnica athm50x really worth buy rea...</td>\n",
       "      <td>[hey, audiotechnica, athm50x, really, worth, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1129 rows Ã— 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "hp.reset_index(drop=True)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text  english  \\\n",
       "0     I am also a big fan of Beyerdynamic, I LOVE my...     True   \n",
       "1     The 880s are a very unique and special headpho...     True   \n",
       "2      @In The Mix  Im considering buying  the DT770...     True   \n",
       "3      @In The Mix  I use 770s for DJing since I nee...     True   \n",
       "4                   Producer collab? Maybe? No? Ok...ðŸ˜‚ðŸ˜‚     True   \n",
       "...                                                 ...      ...   \n",
       "1124  The wrong title for sure because what is best ...     True   \n",
       "1125  buy a cheap headphones. slap on sonarworks and...     True   \n",
       "1126  I purchased m40x yesterday and wasn't satisfie...     True   \n",
       "1127  Compared to the beats headphones which blast b...     True   \n",
       "1128  Hey,  is Audio-Technica ATH-M50X really worth ...     True   \n",
       "\n",
       "                                                  lemma  \\\n",
       "0     also big fan beyerdynamic love dt880s pro make...   \n",
       "1     880s unique and special headphone take time ge...   \n",
       "2      mix consider buy dt770 produce go thanks mention   \n",
       "3     mix use 770s djing since need isolation and 99...   \n",
       "4                           producer collab maybe no ok   \n",
       "...                                                 ...   \n",
       "1124  wrong title sure best production and mixing al...   \n",
       "1125  buy cheap headphone slap sonarworks and make b...   \n",
       "1126  purchase m40x yesterday and satisfied bass lik...   \n",
       "1127  compare beat headphone blast bass m40x flat so...   \n",
       "1128  hey audiotechnica athm50x really worth buy rea...   \n",
       "\n",
       "                                                  token  \n",
       "0     [also, big, fan, beyerdynamic, love, dt880s, p...  \n",
       "1     [880s, unique, and, special, headphone, take, ...  \n",
       "2     [mix, consider, buy, dt770, produce, go, thank...  \n",
       "3     [mix, use, 770s, djing, since, need, isolation...  \n",
       "4                     [producer, collab, maybe, no, ok]  \n",
       "...                                                 ...  \n",
       "1124  [wrong, title, sure, best, production, and, mi...  \n",
       "1125  [buy, cheap, headphone, slap, sonarworks, and,...  \n",
       "1126  [purchase, m40x, yesterday, and, satisfied, ba...  \n",
       "1127  [compare, beat, headphone, blast, bass, m40x, ...  \n",
       "1128  [hey, audiotechnica, athm50x, really, worth, b...  \n",
       "\n",
       "[1129 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>english</th>\n",
       "      <th>lemma</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am also a big fan of Beyerdynamic, I LOVE my...</td>\n",
       "      <td>True</td>\n",
       "      <td>also big fan beyerdynamic love dt880s pro make...</td>\n",
       "      <td>[also, big, fan, beyerdynamic, love, dt880s, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The 880s are a very unique and special headpho...</td>\n",
       "      <td>True</td>\n",
       "      <td>880s unique and special headphone take time ge...</td>\n",
       "      <td>[880s, unique, and, special, headphone, take, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@In The Mix  Im considering buying  the DT770...</td>\n",
       "      <td>True</td>\n",
       "      <td>mix consider buy dt770 produce go thanks mention</td>\n",
       "      <td>[mix, consider, buy, dt770, produce, go, thank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@In The Mix  I use 770s for DJing since I nee...</td>\n",
       "      <td>True</td>\n",
       "      <td>mix use 770s djing since need isolation and 99...</td>\n",
       "      <td>[mix, use, 770s, djing, since, need, isolation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Producer collab? Maybe? No? Ok...ðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>True</td>\n",
       "      <td>producer collab maybe no ok</td>\n",
       "      <td>[producer, collab, maybe, no, ok]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>The wrong title for sure because what is best ...</td>\n",
       "      <td>True</td>\n",
       "      <td>wrong title sure best production and mixing al...</td>\n",
       "      <td>[wrong, title, sure, best, production, and, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>buy a cheap headphones. slap on sonarworks and...</td>\n",
       "      <td>True</td>\n",
       "      <td>buy cheap headphone slap sonarworks and make b...</td>\n",
       "      <td>[buy, cheap, headphone, slap, sonarworks, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>I purchased m40x yesterday and wasn't satisfie...</td>\n",
       "      <td>True</td>\n",
       "      <td>purchase m40x yesterday and satisfied bass lik...</td>\n",
       "      <td>[purchase, m40x, yesterday, and, satisfied, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>Compared to the beats headphones which blast b...</td>\n",
       "      <td>True</td>\n",
       "      <td>compare beat headphone blast bass m40x flat so...</td>\n",
       "      <td>[compare, beat, headphone, blast, bass, m40x, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>Hey,  is Audio-Technica ATH-M50X really worth ...</td>\n",
       "      <td>True</td>\n",
       "      <td>hey audiotechnica athm50x really worth buy rea...</td>\n",
       "      <td>[hey, audiotechnica, athm50x, really, worth, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1129 rows Ã— 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Identify the most frequent words"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# spaCy is a library for advanced Natural Language Processing\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### spacy library used to identify organizations and products that appear the most"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def named_entity_barchart(text):    \n",
    "    def _get_ner(text):\n",
    "        doc=nlp(text)\n",
    "        return [X.label_ for X in doc.ents]\n",
    "    \n",
    "    ent=text.apply(lambda x : _get_ner(x))\n",
    "    ent=[x for sub in ent for x in sub]\n",
    "    counter=Counter(ent)\n",
    "    return counter.most_common()   \n",
    "    \n",
    "print('RAW:', *named_entity_barchart(hp.text), sep='\\n')\n",
    "print('LEMMA:', *named_entity_barchart(hp.lemma), sep='\\n')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RAW:\n",
      "('CARDINAL', 407)\n",
      "('ORG', 399)\n",
      "('PERSON', 226)\n",
      "('DATE', 213)\n",
      "('PRODUCT', 121)\n",
      "('GPE', 96)\n",
      "('MONEY', 67)\n",
      "('ORDINAL', 63)\n",
      "('NORP', 39)\n",
      "('TIME', 23)\n",
      "('LOC', 15)\n",
      "('WORK_OF_ART', 13)\n",
      "('PERCENT', 11)\n",
      "('FAC', 10)\n",
      "('LAW', 7)\n",
      "('EVENT', 6)\n",
      "('QUANTITY', 2)\n",
      "('LANGUAGE', 1)\n",
      "LEMMA:\n",
      "('CARDINAL', 659)\n",
      "('DATE', 171)\n",
      "('ORDINAL', 62)\n",
      "('ORG', 33)\n",
      "('PERSON', 25)\n",
      "('PRODUCT', 17)\n",
      "('TIME', 17)\n",
      "('GPE', 12)\n",
      "('MONEY', 9)\n",
      "('QUANTITY', 7)\n",
      "('NORP', 5)\n",
      "('FAC', 2)\n",
      "('LANGUAGE', 1)\n",
      "('WORK_OF_ART', 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "#check the cardinal data\n",
    "def most_common_named_entity_barchart(text, entity=\"\"):\n",
    "    def _get_ner(text,ent):\n",
    "        doc=nlp(text)\n",
    "        return [X.text for X in doc.ents if X.label_ == ent]\n",
    "\n",
    "    entity_filtered=text.apply(lambda x: _get_ner(x,entity))\n",
    "    entity_filtered=[i for x in entity_filtered for i in x]\n",
    "    \n",
    "    counter=Counter(entity_filtered)\n",
    "    return counter.most_common(30)    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "print('PRODUCT IN RAW TEXT:', *most_common_named_entity_barchart(hp.text, entity=\"PRODUCT\"), sep='\\n')\n",
    "\n",
    "print('CARDINAL:', *most_common_named_entity_barchart(hp.lemma, entity=\"CARDINAL\"), sep='\\n')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PRODUCT IN RAW TEXT:\n",
      "('M40x', 23)\n",
      "('M50x', 16)\n",
      "('DT770', 13)\n",
      "('M30x', 12)\n",
      "('M20x', 6)\n",
      "('702s', 3)\n",
      "('HD600', 3)\n",
      "('DT 990', 3)\n",
      "('880s', 2)\n",
      "('990s', 2)\n",
      "('M50s', 2)\n",
      "('HD280', 1)\n",
      "('K90s', 1)\n",
      "('K501', 1)\n",
      "('DT990 Pro', 1)\n",
      "('DT250', 1)\n",
      "('M40s', 1)\n",
      "('MX400', 1)\n",
      "('HD280 Pro  - enough', 1)\n",
      "('K518', 1)\n",
      "('MX', 1)\n",
      "('VS M30X\\r\\n\\r\\n', 1)\n",
      "('880 Pro', 1)\n",
      "('K240', 1)\n",
      "('M1 Macbook Air', 1)\n",
      "('MDR7506', 1)\n",
      "('HD250', 1)\n",
      "('Sony MDR7506', 1)\n",
      "('DaVinci Resolve Studio', 1)\n",
      "('the DT770 Pro', 1)\n",
      "CARDINAL:\n",
      "('770', 113)\n",
      "('one', 80)\n",
      "('990', 34)\n",
      "('250', 33)\n",
      "('80', 28)\n",
      "('7506', 27)\n",
      "('100', 15)\n",
      "('two', 14)\n",
      "('2', 13)\n",
      "('240', 12)\n",
      "('10', 11)\n",
      "('50', 9)\n",
      "('280', 9)\n",
      "('3', 8)\n",
      "('702', 7)\n",
      "('30', 7)\n",
      "('4', 7)\n",
      "('32', 6)\n",
      "('200', 6)\n",
      "('1', 6)\n",
      "('20', 6)\n",
      "('5', 5)\n",
      "('60', 5)\n",
      "('40', 5)\n",
      "('k240', 5)\n",
      "('32 80', 4)\n",
      "('300', 4)\n",
      "('150', 4)\n",
      "('80ohm', 4)\n",
      "('half', 4)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CARDINAL is the entity that appears the most, as we know what our data is about, we can detect that these numbers are, in fact, names (description) of products."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "#the cardinals are part of product names but misspelled,\n",
    "#so let's correct the names and check the above functions again!\n",
    "\n",
    "#Dictionary for product names\n",
    "correct_name = { \n",
    "                \"dt\": \" \", \"audeze\": \"Audeze\", \n",
    "                \"a7x\": \"A7X\", \"dt250\": \"DT250\",   \n",
    "                \"oneodio\": \"OneOdio\", \"apple\": \"Apple\",\n",
    "                \"the dt770 pro\": \"DT770 Pro\", \"770pro\": \"DT770 Pro\",\n",
    "                \"dt770s\": \"DT770\", \"770s\": \"DT770\", \"770\": \"DT770\", \n",
    "                \"dt880s pro\": \"DT880 Pro\", \"dt880s\": \"DT880\", \"880s\": \"DT880\",\n",
    "                \"880 pro\": \"DT800 Pro\", \"880\": \"DT880\",\n",
    "                \"dt990\": \"DT990\", \"990s\": \"DT990\", \"990\": \"DT990\",\n",
    "                \"xm3\": \"XM3\", \"m40x\": \"M40x\", \"m50x\": \"M50x\",\n",
    "                \"m30x\": \"M30x\", \"m20x\": \"M20x\", \"mx400\": \"MX400\", \"m50s\": \"M50s\",\n",
    "                \"702s\": \"k702\", \"hd600\": \"HD600\",\n",
    "                \"hd 600\": \"HD600\", \"k90s\": \"K90s\", \"k501\":\"K501\", \"k518\": \"k518\",\n",
    "                \"mdr 7506\": \"MDR7506\", \"7506\": \"MDR7506\", \"k702\": \"K702\", \"k240\": \"K240\",\n",
    "                \"sennheiser\": \"Sennheiser\", \"sony\": \"Sony\", \"audio technica\": \"ATH\",\n",
    "                \"Audio-Technica\": \"ATH\", \"audiotechnica\": \"ATH\",\n",
    "                \"beyerdynamic\": \"Beyer\", \"beyers\": \"Beyer\", \"beyer\": \"Beyer\", \"beyers\": \"Beyer\",\n",
    "                \"akg \": \"AKG \", \"akg\": \"AKG \", \"amazon\": \"Amazon\", \"bose\": \"Bose\", \"ATH-M50X\": \"ATH M50x\",\n",
    "                \"ath \": \"ATH\", \"ath\": \"ATH \", \"ath m40x\": \"ATH M40x\", \"athm40x\": \"ATH M40x\",  \"hd 280s\": \"HD 280\", \"hd280\": \"HD 280\",\n",
    "                \"jbl\": \"JBL\", \"samsung\": \"Samsung\", \"samson\": \"Samson\", \"sm50\": \"SM50\", \"claw\": \"Claw\", \"sr850\": \"SR850\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#substitute wrong words for the correct ones.\n",
    "def other_cleaning(df):\n",
    "    \"\"\"Functions to replace wrong writings with correct\n",
    "    \"\"\"\n",
    "    def correct_product(self, correct_name=correct_name):\n",
    "        # Regular expression for finding product_name\n",
    "        correct_re=re.compile('(%s)' % '|'.join(correct_name.keys()))\n",
    "        def replace(match):\n",
    "            return correct_name[match.group(0)]\n",
    "        return correct_re.sub(replace, self)\n",
    "    df['remove_symbols'] = df['text'].apply(remove_symbols)\n",
    "    df['text_products'] = df['remove_symbols'].apply(correct_product)\n",
    "    df['lemma_w_product'] = df['lemma'].apply(correct_product)   \n",
    "    df = df.drop(['remove_symbols'], axis='columns', inplace=True)\n",
    "    return df\n",
    "    \n",
    "other_cleaning(hp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "hp.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  english  \\\n",
       "0  I am also a big fan of Beyerdynamic, I LOVE my...     True   \n",
       "1  The 880s are a very unique and special headpho...     True   \n",
       "3   @In The Mix  Im considering buying  the DT770...     True   \n",
       "4   @In The Mix  I use 770s for DJing since I nee...     True   \n",
       "5                Producer collab? Maybe? No? Ok...ðŸ˜‚ðŸ˜‚     True   \n",
       "\n",
       "                                               lemma  \\\n",
       "0  also big fan beyerdynamic love dt880s pro make...   \n",
       "1  880s unique and special headphone take time ge...   \n",
       "3   mix consider buy dt770 produce go thanks mention   \n",
       "4  mix use 770s djing since need isolation and 99...   \n",
       "5                        producer collab maybe no ok   \n",
       "\n",
       "                                               token  \\\n",
       "0  [also, big, fan, beyerdynamic, love, dt880s, p...   \n",
       "1  [880s, unique, and, special, headphone, take, ...   \n",
       "3  [mix, consider, buy, dt770, produce, go, thank...   \n",
       "4  [mix, use, 770s, djing, since, need, isolation...   \n",
       "5                  [producer, collab, maybe, no, ok]   \n",
       "\n",
       "                                       text_products  \\\n",
       "0  I am also a big fan of Beyerdynamic I LOVE my ...   \n",
       "1  The DT880 are a very unique and special headph...   \n",
       "3    The Mix  Im considering buying  the DTDT770 ...   \n",
       "4    The Mix  I use DT770 for DJing since I need ...   \n",
       "5                        Producer collab Maybe No Ok   \n",
       "\n",
       "                                     lemma_w_product  \n",
       "0  also big fan Beyer love  DT880 pro make full p...  \n",
       "1  DT880 unique and special headphone take time g...  \n",
       "3  mix consider buy  DT770 produce go thanks mention  \n",
       "4  mix use DT770 djing since need isolation and D...  \n",
       "5                        producer collab maybe no ok  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>english</th>\n",
       "      <th>lemma</th>\n",
       "      <th>token</th>\n",
       "      <th>text_products</th>\n",
       "      <th>lemma_w_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am also a big fan of Beyerdynamic, I LOVE my...</td>\n",
       "      <td>True</td>\n",
       "      <td>also big fan beyerdynamic love dt880s pro make...</td>\n",
       "      <td>[also, big, fan, beyerdynamic, love, dt880s, p...</td>\n",
       "      <td>I am also a big fan of Beyerdynamic I LOVE my ...</td>\n",
       "      <td>also big fan Beyer love  DT880 pro make full p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The 880s are a very unique and special headpho...</td>\n",
       "      <td>True</td>\n",
       "      <td>880s unique and special headphone take time ge...</td>\n",
       "      <td>[880s, unique, and, special, headphone, take, ...</td>\n",
       "      <td>The DT880 are a very unique and special headph...</td>\n",
       "      <td>DT880 unique and special headphone take time g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@In The Mix  Im considering buying  the DT770...</td>\n",
       "      <td>True</td>\n",
       "      <td>mix consider buy dt770 produce go thanks mention</td>\n",
       "      <td>[mix, consider, buy, dt770, produce, go, thank...</td>\n",
       "      <td>The Mix  Im considering buying  the DTDT770 ...</td>\n",
       "      <td>mix consider buy  DT770 produce go thanks mention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@In The Mix  I use 770s for DJing since I nee...</td>\n",
       "      <td>True</td>\n",
       "      <td>mix use 770s djing since need isolation and 99...</td>\n",
       "      <td>[mix, use, 770s, djing, since, need, isolation...</td>\n",
       "      <td>The Mix  I use DT770 for DJing since I need ...</td>\n",
       "      <td>mix use DT770 djing since need isolation and D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Producer collab? Maybe? No? Ok...ðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>True</td>\n",
       "      <td>producer collab maybe no ok</td>\n",
       "      <td>[producer, collab, maybe, no, ok]</td>\n",
       "      <td>Producer collab Maybe No Ok</td>\n",
       "      <td>producer collab maybe no ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking most common products entities before and after cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "\n",
    "print('Products in raw data:', *most_common_named_entity_barchart(hp.text, entity=\"PRODUCT\"), sep='\\n')\n",
    "print('Products in not so raw:', *most_common_named_entity_barchart(hp.text_products, entity=\"PRODUCT\"), sep='\\n')\n",
    "print('Products in normalized data:', *most_common_named_entity_barchart(hp.lemma_w_product, entity=\"PRODUCT\"), sep='\\n')\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Products in raw data:\n",
      "('M40x', 23)\n",
      "('M50x', 16)\n",
      "('DT770', 13)\n",
      "('M30x', 12)\n",
      "('M20x', 6)\n",
      "('702s', 3)\n",
      "('HD600', 3)\n",
      "('DT 990', 3)\n",
      "('880s', 2)\n",
      "('990s', 2)\n",
      "('M50s', 2)\n",
      "('HD280', 1)\n",
      "('K90s', 1)\n",
      "('K501', 1)\n",
      "('DT990 Pro', 1)\n",
      "('DT250', 1)\n",
      "('M40s', 1)\n",
      "('MX400', 1)\n",
      "('HD280 Pro  - enough', 1)\n",
      "('K518', 1)\n",
      "('MX', 1)\n",
      "('VS M30X\\r\\n\\r\\n', 1)\n",
      "('880 Pro', 1)\n",
      "('K240', 1)\n",
      "('M1 Macbook Air', 1)\n",
      "('MDR7506', 1)\n",
      "('HD250', 1)\n",
      "('Sony MDR7506', 1)\n",
      "('DaVinci Resolve Studio', 1)\n",
      "('the DT770 Pro', 1)\n",
      "Products in not so raw:\n",
      "('M50x', 43)\n",
      "('M40x', 43)\n",
      "('DT770', 34)\n",
      "('M30x', 19)\n",
      "('MDR7506', 9)\n",
      "('M20x', 9)\n",
      "('DT DT770', 6)\n",
      "('M50s', 5)\n",
      "('HD600', 3)\n",
      "('DT DT990', 3)\n",
      "('ATH M40x', 3)\n",
      "('DT880', 2)\n",
      "('M40s', 2)\n",
      "('DT770 Pro', 2)\n",
      "('DT DT770 Pro', 2)\n",
      "('HD25', 1)\n",
      "('HD280', 1)\n",
      "('HD300 Anything', 1)\n",
      "('K90s', 1)\n",
      "('the M40x Amazing', 1)\n",
      "('K501', 1)\n",
      "('DT250', 1)\n",
      "('MX400', 1)\n",
      "('MDR MDR7506', 1)\n",
      "('HD280 Pro  ', 1)\n",
      "('MX', 1)\n",
      "('VS M30X\\r\\n\\r\\n', 1)\n",
      "('the M40x Great', 1)\n",
      "('K44s', 1)\n",
      "('940s', 1)\n",
      "Products in normalized data:\n",
      "('M40x', 61)\n",
      "('DT770', 54)\n",
      "('M50x', 47)\n",
      "('M30x', 25)\n",
      "('MDR7506', 21)\n",
      "('M20x', 10)\n",
      "('DT990', 6)\n",
      "('HD600', 6)\n",
      "('ATH M40x', 6)\n",
      "('DT880', 3)\n",
      "('M50s', 3)\n",
      "('DT770 Pro', 3)\n",
      "('K240', 3)\n",
      "('ATH ATH', 2)\n",
      "('DT800 Pro', 2)\n",
      "('Claw SM50', 2)\n",
      "('ATH M50x', 2)\n",
      "('DT880 DT990', 2)\n",
      "('K90s', 1)\n",
      "('K501', 1)\n",
      "('MX400', 1)\n",
      "('XM3', 1)\n",
      "('240mk', 1)\n",
      "('M40x 20', 1)\n",
      "('Beyerdynanic', 1)\n",
      "('M30x 14190', 1)\n",
      "('M40x M50x', 1)\n",
      "('ATH ATH avc500', 1)\n",
      "('ATH 30', 1)\n",
      "('ATH 40x', 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### As seen above the quantity of products increased considerably after correction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking most common brands entities before and after cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "print('BRAND in raw data:', *most_common_named_entity_barchart(hp.text, entity=\"ORG\"), sep='\\n')\n",
    "print('BRAND in not so raw data:', *most_common_named_entity_barchart(hp.text_products, entity=\"ORG\"), sep='\\n')\n",
    "print('BRAND in normalized data:', *most_common_named_entity_barchart(hp.lemma_w_product, entity=\"ORG\"), sep='\\n')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BRAND in raw data:\n",
      "('Sennheiser', 31)\n",
      "('Sony', 30)\n",
      "('ATH', 14)\n",
      "('Amazon', 12)\n",
      "('K702', 8)\n",
      "('EQ', 7)\n",
      "('Beyer', 6)\n",
      "('M40', 5)\n",
      "('AKG', 5)\n",
      "('DT', 5)\n",
      "('K240', 5)\n",
      "('Samsung', 5)\n",
      "('Beyers', 4)\n",
      "('MDR', 4)\n",
      "('k240', 4)\n",
      "('OHM', 4)\n",
      "('The Sony MDR 7506', 3)\n",
      "('M30', 3)\n",
      "('LOL', 3)\n",
      "('DAW', 3)\n",
      "('Samson', 3)\n",
      "('@Cache', 3)\n",
      "('DAC', 3)\n",
      "('YouTube', 3)\n",
      "('ðŸ‘Œ', 3)\n",
      "('M30X', 3)\n",
      "('the Sonyâ€™s', 2)\n",
      "('@Fisher', 2)\n",
      "('EDM', 2)\n",
      "('Audeze', 2)\n",
      "BRAND in not so raw data:\n",
      "('Sennheiser', 34)\n",
      "('Sony', 23)\n",
      "('ATH', 22)\n",
      "('Beyer', 20)\n",
      "('Amazon', 17)\n",
      "('Beyers', 8)\n",
      "('K240', 8)\n",
      "('EQ', 7)\n",
      "('K702', 6)\n",
      "('Samson', 6)\n",
      "('Apple', 5)\n",
      "('Samsung', 5)\n",
      "('OneOdio', 4)\n",
      "('M40', 4)\n",
      "('MDR', 4)\n",
      "('DT', 4)\n",
      "('OHM', 4)\n",
      "('Ill', 3)\n",
      "('LOL', 3)\n",
      "('YouTube', 3)\n",
      "('VModa', 3)\n",
      "('AudioTechnica', 3)\n",
      "('M30', 2)\n",
      "('AKG', 2)\n",
      "('EDM', 2)\n",
      "('DT770', 2)\n",
      "('Audeze', 2)\n",
      "('the Philips SHP9500', 2)\n",
      "('the Audio Technica M30x', 2)\n",
      "('HD650', 2)\n",
      "BRAND in normalized data:\n",
      "('ATH', 55)\n",
      "('Beyer', 46)\n",
      "('Sony', 44)\n",
      "('Sennheiser', 35)\n",
      "('Amazon', 17)\n",
      "('K702', 11)\n",
      "('K240', 10)\n",
      "('Beyers', 9)\n",
      "('DT770', 6)\n",
      "('OneOdio', 5)\n",
      "('Apple', 5)\n",
      "('AKG', 5)\n",
      "('ATH M50x', 5)\n",
      "('Samsung', 5)\n",
      "('Samson SR850', 4)\n",
      "('Samson', 4)\n",
      "('ATH ATH M50x', 4)\n",
      "('Audeze', 3)\n",
      "('Sonys', 2)\n",
      "('ATH M30x', 2)\n",
      "('ATH ATH', 1)\n",
      "('th02', 1)\n",
      "('M40x', 1)\n",
      "('Amazon 280', 1)\n",
      "('Samson SR850s', 1)\n",
      "('ATHmarket', 1)\n",
      "('Beyer bt240', 1)\n",
      "('K702 DT770', 1)\n",
      "('Amazon DT770', 1)\n",
      "('ATHgreat', 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def product_list(text, entity=\"\"):\n",
    "    def _get_ner(text,ent):\n",
    "        doc=nlp(text)\n",
    "        return [X.text for X in doc.ents if X.label_ == ent]\n",
    "\n",
    "    entity_filtered=text.apply(lambda x: _get_ner(x,entity))\n",
    "    entity_filtered=[i for x in entity_filtered for i in x]\n",
    "    \n",
    "    counter=Counter(entity_filtered)\n",
    "    return counter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "products = list(product_list(hp.lemma_w_product, entity=\"ORG\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "products"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Amazon',\n",
       " 'Sennheiser',\n",
       " 'Sony',\n",
       " 'Beyers',\n",
       " 'ATH',\n",
       " 'DT770',\n",
       " 'Beyer',\n",
       " 'K702',\n",
       " 'OneOdio',\n",
       " 'Audeze',\n",
       " 'Samson SR850',\n",
       " 'Apple',\n",
       " 'K240',\n",
       " 'AKG',\n",
       " 'ATH ATH',\n",
       " 'th02',\n",
       " 'M40x',\n",
       " 'Amazon 280',\n",
       " 'Samson',\n",
       " 'Sonys',\n",
       " 'ATH M50x',\n",
       " 'Samson SR850s',\n",
       " 'Samsung',\n",
       " 'ATH M30x',\n",
       " 'ATHmarket',\n",
       " 'Beyer bt240',\n",
       " 'K702 DT770',\n",
       " 'Amazon DT770',\n",
       " 'ATHgreat',\n",
       " 'Sony Sennheisers',\n",
       " 'k612pro',\n",
       " 'Beyers DT770',\n",
       " 'Bose qc35',\n",
       " 'JBL',\n",
       " 'ATH ATH M50x',\n",
       " 'Beyer DT770',\n",
       " 'ATH ATHg1',\n",
       " 'Amazon half',\n",
       " 'Sennheiser hd650']"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### As seen above some brands need better treatment as spacy identifies them along with the product name"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create column with products and brands for future insights"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "\n",
    "\n",
    "def add_column_for_name(df, names_list, text_column):\n",
    "    \"\"\"\n",
    "    Add column(s) that indicates whether name(s) is/are in text_column\n",
    "    Args:\n",
    "        df: pandas dataframe\n",
    "        product_list: list of strings (names) \n",
    "        text_column: column containing text\n",
    "    Returns:\n",
    "        df with column of Booleans \n",
    "    \"\"\"\n",
    "    for name in names_list:\n",
    "        hp[name] = hp['lemma_w_product'].apply(lambda x: word_in_text(name, x))\n",
    "    return df\n",
    "\n",
    "def word_in_text(word, text):\n",
    "    \"\"\"\n",
    "    Function to make text lower case and return True if a term is present,\n",
    "    False otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    match = re.search(word, text)\n",
    "    if match:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "add_column_for_name(hp, products, 'lemma_w_product')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text  english  \\\n",
       "0     I am also a big fan of Beyerdynamic, I LOVE my...     True   \n",
       "1     The 880s are a very unique and special headpho...     True   \n",
       "3      @In The Mix  Im considering buying  the DT770...     True   \n",
       "4      @In The Mix  I use 770s for DJing since I nee...     True   \n",
       "5                   Producer collab? Maybe? No? Ok...ðŸ˜‚ðŸ˜‚     True   \n",
       "...                                                 ...      ...   \n",
       "1361  The wrong title for sure because what is best ...     True   \n",
       "1362  buy a cheap headphones. slap on sonarworks and...     True   \n",
       "1363  I purchased m40x yesterday and wasn't satisfie...     True   \n",
       "1364  Compared to the beats headphones which blast b...     True   \n",
       "1365  Hey,  is Audio-Technica ATH-M50X really worth ...     True   \n",
       "\n",
       "                                                  lemma  \\\n",
       "0     also big fan beyerdynamic love dt880s pro make...   \n",
       "1     880s unique and special headphone take time ge...   \n",
       "3      mix consider buy dt770 produce go thanks mention   \n",
       "4     mix use 770s djing since need isolation and 99...   \n",
       "5                           producer collab maybe no ok   \n",
       "...                                                 ...   \n",
       "1361  wrong title sure best production and mixing al...   \n",
       "1362  buy cheap headphone slap sonarworks and make b...   \n",
       "1363  purchase m40x yesterday and satisfied bass lik...   \n",
       "1364  compare beat headphone blast bass m40x flat so...   \n",
       "1365  hey audiotechnica athm50x really worth buy rea...   \n",
       "\n",
       "                                                  token  \\\n",
       "0     [also, big, fan, beyerdynamic, love, dt880s, p...   \n",
       "1     [880s, unique, and, special, headphone, take, ...   \n",
       "3     [mix, consider, buy, dt770, produce, go, thank...   \n",
       "4     [mix, use, 770s, djing, since, need, isolation...   \n",
       "5                     [producer, collab, maybe, no, ok]   \n",
       "...                                                 ...   \n",
       "1361  [wrong, title, sure, best, production, and, mi...   \n",
       "1362  [buy, cheap, headphone, slap, sonarworks, and,...   \n",
       "1363  [purchase, m40x, yesterday, and, satisfied, ba...   \n",
       "1364  [compare, beat, headphone, blast, bass, m40x, ...   \n",
       "1365  [hey, audiotechnica, athm50x, really, worth, b...   \n",
       "\n",
       "                                          text_products  \\\n",
       "0     I am also a big fan of Beyerdynamic I LOVE my ...   \n",
       "1     The DT880 are a very unique and special headph...   \n",
       "3       The Mix  Im considering buying  the DTDT770 ...   \n",
       "4       The Mix  I use DT770 for DJing since I need ...   \n",
       "5                           Producer collab Maybe No Ok   \n",
       "...                                                 ...   \n",
       "1361  The wrong title for sure because what is best ...   \n",
       "1362  buy a cheap headphones slap on sonarworks and ...   \n",
       "1363  I purchased M40x yesterday and wasnt satisfied...   \n",
       "1364  Compared to the beats headphones which blast b...   \n",
       "1365  Hey  is AudioTechnica ATHM50X really worth to ...   \n",
       "\n",
       "                                        lemma_w_product  Amazon  Sennheiser  \\\n",
       "0     also big fan Beyer love  DT880 pro make full p...   False       False   \n",
       "1     DT880 unique and special headphone take time g...   False       False   \n",
       "3     mix consider buy  DT770 produce go thanks mention   False       False   \n",
       "4     mix use DT770 djing since need isolation and D...   False       False   \n",
       "5                           producer collab maybe no ok   False       False   \n",
       "...                                                 ...     ...         ...   \n",
       "1361  wrong title sure best production and mixing al...   False       False   \n",
       "1362  buy cheap headphone slap sonarworks and make b...   False       False   \n",
       "1363  purchase M40x yesterday and satisfied bass lik...   False       False   \n",
       "1364  compare beat headphone blast bass M40x flat so...   False       False   \n",
       "1365  hey ATH ATH M50x really worth buy really good ...   False       False   \n",
       "\n",
       "       Sony  Beyers  ...  Sony Sennheisers  k612pro  Beyers DT770  Bose qc35  \\\n",
       "0     False   False  ...             False    False         False      False   \n",
       "1     False   False  ...             False    False         False      False   \n",
       "3     False   False  ...             False    False         False      False   \n",
       "4     False   False  ...             False    False         False      False   \n",
       "5     False   False  ...             False    False         False      False   \n",
       "...     ...     ...  ...               ...      ...           ...        ...   \n",
       "1361  False   False  ...             False    False         False      False   \n",
       "1362  False   False  ...             False    False         False      False   \n",
       "1363  False   False  ...             False    False         False      False   \n",
       "1364  False   False  ...             False    False         False      False   \n",
       "1365  False   False  ...             False    False         False      False   \n",
       "\n",
       "        JBL  ATH ATH M50x  Beyer DT770  ATH ATHg1  Amazon half  \\\n",
       "0     False         False        False      False        False   \n",
       "1     False         False        False      False        False   \n",
       "3     False         False        False      False        False   \n",
       "4     False         False        False      False        False   \n",
       "5     False         False        False      False        False   \n",
       "...     ...           ...          ...        ...          ...   \n",
       "1361  False         False        False      False        False   \n",
       "1362  False         False        False      False        False   \n",
       "1363  False         False        False      False        False   \n",
       "1364  False         False        False      False        False   \n",
       "1365  False          True        False      False        False   \n",
       "\n",
       "      Sennheiser hd650  \n",
       "0                False  \n",
       "1                False  \n",
       "3                False  \n",
       "4                False  \n",
       "5                False  \n",
       "...                ...  \n",
       "1361             False  \n",
       "1362             False  \n",
       "1363             False  \n",
       "1364             False  \n",
       "1365             False  \n",
       "\n",
       "[1129 rows x 45 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>english</th>\n",
       "      <th>lemma</th>\n",
       "      <th>token</th>\n",
       "      <th>text_products</th>\n",
       "      <th>lemma_w_product</th>\n",
       "      <th>Amazon</th>\n",
       "      <th>Sennheiser</th>\n",
       "      <th>Sony</th>\n",
       "      <th>Beyers</th>\n",
       "      <th>...</th>\n",
       "      <th>Sony Sennheisers</th>\n",
       "      <th>k612pro</th>\n",
       "      <th>Beyers DT770</th>\n",
       "      <th>Bose qc35</th>\n",
       "      <th>JBL</th>\n",
       "      <th>ATH ATH M50x</th>\n",
       "      <th>Beyer DT770</th>\n",
       "      <th>ATH ATHg1</th>\n",
       "      <th>Amazon half</th>\n",
       "      <th>Sennheiser hd650</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am also a big fan of Beyerdynamic, I LOVE my...</td>\n",
       "      <td>True</td>\n",
       "      <td>also big fan beyerdynamic love dt880s pro make...</td>\n",
       "      <td>[also, big, fan, beyerdynamic, love, dt880s, p...</td>\n",
       "      <td>I am also a big fan of Beyerdynamic I LOVE my ...</td>\n",
       "      <td>also big fan Beyer love  DT880 pro make full p...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The 880s are a very unique and special headpho...</td>\n",
       "      <td>True</td>\n",
       "      <td>880s unique and special headphone take time ge...</td>\n",
       "      <td>[880s, unique, and, special, headphone, take, ...</td>\n",
       "      <td>The DT880 are a very unique and special headph...</td>\n",
       "      <td>DT880 unique and special headphone take time g...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@In The Mix  Im considering buying  the DT770...</td>\n",
       "      <td>True</td>\n",
       "      <td>mix consider buy dt770 produce go thanks mention</td>\n",
       "      <td>[mix, consider, buy, dt770, produce, go, thank...</td>\n",
       "      <td>The Mix  Im considering buying  the DTDT770 ...</td>\n",
       "      <td>mix consider buy  DT770 produce go thanks mention</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@In The Mix  I use 770s for DJing since I nee...</td>\n",
       "      <td>True</td>\n",
       "      <td>mix use 770s djing since need isolation and 99...</td>\n",
       "      <td>[mix, use, 770s, djing, since, need, isolation...</td>\n",
       "      <td>The Mix  I use DT770 for DJing since I need ...</td>\n",
       "      <td>mix use DT770 djing since need isolation and D...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Producer collab? Maybe? No? Ok...ðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>True</td>\n",
       "      <td>producer collab maybe no ok</td>\n",
       "      <td>[producer, collab, maybe, no, ok]</td>\n",
       "      <td>Producer collab Maybe No Ok</td>\n",
       "      <td>producer collab maybe no ok</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>The wrong title for sure because what is best ...</td>\n",
       "      <td>True</td>\n",
       "      <td>wrong title sure best production and mixing al...</td>\n",
       "      <td>[wrong, title, sure, best, production, and, mi...</td>\n",
       "      <td>The wrong title for sure because what is best ...</td>\n",
       "      <td>wrong title sure best production and mixing al...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>buy a cheap headphones. slap on sonarworks and...</td>\n",
       "      <td>True</td>\n",
       "      <td>buy cheap headphone slap sonarworks and make b...</td>\n",
       "      <td>[buy, cheap, headphone, slap, sonarworks, and,...</td>\n",
       "      <td>buy a cheap headphones slap on sonarworks and ...</td>\n",
       "      <td>buy cheap headphone slap sonarworks and make b...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>I purchased m40x yesterday and wasn't satisfie...</td>\n",
       "      <td>True</td>\n",
       "      <td>purchase m40x yesterday and satisfied bass lik...</td>\n",
       "      <td>[purchase, m40x, yesterday, and, satisfied, ba...</td>\n",
       "      <td>I purchased M40x yesterday and wasnt satisfied...</td>\n",
       "      <td>purchase M40x yesterday and satisfied bass lik...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>Compared to the beats headphones which blast b...</td>\n",
       "      <td>True</td>\n",
       "      <td>compare beat headphone blast bass m40x flat so...</td>\n",
       "      <td>[compare, beat, headphone, blast, bass, m40x, ...</td>\n",
       "      <td>Compared to the beats headphones which blast b...</td>\n",
       "      <td>compare beat headphone blast bass M40x flat so...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>Hey,  is Audio-Technica ATH-M50X really worth ...</td>\n",
       "      <td>True</td>\n",
       "      <td>hey audiotechnica athm50x really worth buy rea...</td>\n",
       "      <td>[hey, audiotechnica, athm50x, really, worth, b...</td>\n",
       "      <td>Hey  is AudioTechnica ATHM50X really worth to ...</td>\n",
       "      <td>hey ATH ATH M50x really worth buy really good ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1129 rows Ã— 45 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# pickle save df\n",
    "Project_path = \"analysis\"\n",
    "model_path = Project_path + \"/models/\"\n",
    "def save_pkl_pickle(model_path):\n",
    "    pickle.dump(hp, open(model_path+\"hp_data.pickle\", 'wb'))\n",
    "    print (\"====done saving into pickle using Pickle!====\")\n",
    "save_pkl_pickle(model_path)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "1c6a9db5200fe975c7ec936b1d3602ba8fe785f94dde53a71703ed1236872a51"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}